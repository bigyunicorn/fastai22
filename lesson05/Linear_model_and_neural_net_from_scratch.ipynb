{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNmj/sqz3ZinWLQnMniaN4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigyunicorn/fastai22/blob/main/lesson05/Linear_model_and_neural_net_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "I reorganized Jeremy's Notebook for [FastAI lesson05](https://www.kaggle.com/code/bigyunicorn/linear-model-and-neural-net-from-scratch/edit) so that my future self can easily recall the content and leverage it in the future.\n",
        "\n",
        "I am mainly focusing on the high level key points from the notes. All the code is directly coming from the Jeremy's notebook.\n",
        "\n",
        "___\n",
        "#### Notes:\n",
        "I wanted to use the coding aspect leveraing an AI coding tool such as copilot or codey. Unfortunately, I do not have the access to the GPU supported GitHub Codespce or the access to Codey in Google Colab as of now (06/21/23).\n",
        "\n",
        "I am planning to try it once either of the feature is available to me. I've tried creating [my notebook](https://github.com/bigyunicorn/fastai22/blob/main/lesson03/neural-network-from-scratch.ipynb) from the scratch by using github copilot for FastAI lesson 03. It was very helpful as I could focus on the essense of each notebook that Jeremy goes over in the lecture without worrying about the syntax too much.\n",
        "\n",
        "I highly recommend trying this method out to others if you have access.\n",
        "___\n",
        "#### Tips for taking the FastAI course.\n",
        "- Watch a lecture e2e one time.\n",
        "- Copy each given notebook and follow through on your own.\n",
        "- Think about main steps from the notebook and write those down (I usually use these main steps as the title of each section).\n",
        "- Expand each of the main steps and break it down smaller steps so you can easily ask the copilot to write the code.\n",
        "- Reproduce the results.\n",
        "- Publish your notebook to github.\n"
      ],
      "metadata": {
        "id": "5TUy79xz5MYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A few key points from the lesson 05\n",
        "\n",
        "\n",
        "* To me, the purpose of the chapter 5 is to show how to create a deep learning model from the scratch by setting up a linear model and a neural net first and then expanding them to create a deep learning model.\n",
        "* We are simply using plain python and pytroch to create the model so that we can understand the pains of not using the framework such as FastAI.\n",
        " - In the chapter 4, we used the hugging face library to train the existing model. For the previous chapters, we used fastai. But here, we are only relying on python and pytorch (To be 100% correct, we use the fast ai library once to create a validation set. We learned about how to create a meaningful validation set from the scratch in [Iterate like a grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/#Creating-a-validation-set).\n",
        "- Spoiler: It is painful as we need to figure out how to do initialization, normalization and learning rate from the scratch. The cost of this pain is that it is making hard for people to experiment more.\n",
        "- We will go through the same procdess but using the framework in our [second notebook](https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework)\n",
        "\n",
        "# Important Context\n",
        "* The given problem we are going to use:\n",
        "  - We are tasked to predict which passengers survived the Titanic shipwreck.\n",
        "  - This is a very beginner frinedly kaggle competition. [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/overview/evaluation).\n",
        "  - You can find the data here: https://www.kaggle.com/competitions/titanic/data\n",
        "  - The metric(evaluation) we are going to use is accuracy. You can find the information in the [evaluation](https://www.kaggle.com/competitions/titanic/overview/evaluation) tab.\n",
        "* This is the same data we used for the [Lesson 03](https://course.fast.ai/Lessons/lesson3.html) where we created a neural net from the scratch in the excel.\n",
        "  - You can find my notes for this lesson here: https://github.com/bigyunicorn/fastai22/blob/main/lesson03/titanic-data-visualization.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "v1TL39r47gBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up:\n",
        "- Make sure your kernel is running on GPU.\n",
        "- Get Kaggle API key from Kaggle (it will download kaggle.json).\n",
        "- Copy the key value and put it in the right below cell.\n",
        "- More details: https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners#Introduction"
      ],
      "metadata": {
        "id": "b871Ta7-C4U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creds = '{\"username\":\"<your kaggle user name>\",\"key\":\"<your kaggle api key>\"}'"
      ],
      "metadata": {
        "id": "9AvIARfEDJZ-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only need to run once.\n",
        "from pathlib import Path\n",
        "\n",
        "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
        "if not cred_path.exists():\n",
        "    cred_path.parent.mkdir(exist_ok=True)\n",
        "    cred_path.write_text(creds)\n",
        "    cred_path.chmod(0o600)"
      ],
      "metadata": {
        "id": "hZlA_uZkjbu9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, now ready to use Kaggle API to download the dataset!\n",
        "\n",
        "Let's first install the kaggle package."
      ],
      "metadata": {
        "id": "1VL3cBKiDvdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Get the dataset from Kaggle"
      ],
      "metadata": {
        "id": "Z8SadZ6QFCc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wUsfjsdJio36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3642186-69b1-4214-d21b-30508fe75ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "# install the kaggle package so we can use its API.\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The below is useful code to fetch dataset we are interested in from Kaggle.\n",
        "# you can use the same code if you are on kaggle.\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "if iskaggle: path = Path('../input/titanic')\n",
        "else:\n",
        "    path = Path('titanic') #kaggle dataset data tab has this name at the end.\n",
        "    if not path.exists():\n",
        "        import zipfile,kaggle\n",
        "        kaggle.api.competition_download_cli(str(path)) # this is the kagglge python library API\n",
        "        zipfile.ZipFile(f'{path}.zip').extractall(path) # extract all files from zip"
      ],
      "metadata": {
        "id": "RZ6xR4dGlbRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9556ab-85fd-4304-c2ee-351fda728c46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading titanic.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34.1k/34.1k [00:00<00:00, 1.17MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the below is a bsh command to download the data. Github copilot might recommend this line.\n",
        "\n",
        "`!kaggle competitions download -c titanic`\n",
        "\n",
        "What i just did above is loading the kaggle dataset to google colab. The reason I chose this is a) I prefer google colab over kaggle and b) I think i have flexibility to get more GPU if i need to."
      ],
      "metadata": {
        "id": "2C-lenLkkTSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Check the dataset structure and explore the data."
      ],
      "metadata": {
        "id": "aasabkylFh4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's see the file structure of Kaggle downloaded dataset\n",
        "!ls {path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OTWXZFXB9xo",
        "outputId": "500f8ac4-4bc8-4b10-839c-c5a612561b0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender_submission.csv  test.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once I confirmed that the files are in csv, I am going to use pandas, as it is for handling csv files. Google Colab already installed pandas so I can skip `pip install pandas` and directly import the library as pd."
      ],
      "metadata": {
        "id": "d7FKegt4CwCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Colab has it installed already."
      ],
      "metadata": {
        "id": "TCXPyGv-CKtB"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}